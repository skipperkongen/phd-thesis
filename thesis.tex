\documentclass[11pt, oneside]{report}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or eps with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}

\title{A Declarative Language for Multiscale Data Abstraction of Spatial Datasets}
\author{Pimin Konstantin Kefaloukos}
%\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle

\tableofcontents

\part{Introduction}

\chapter{Multiscale Data Visualizations}

\section{Fundamentals}
On a cave wall in Lascaux, France, a series of dots dating to 16.500 BC have captured the imagination of scholars. These ancient dots are arranged so much like well-known constellations, that some scholars believe them to be a celestial map -- a view of the night sky as seen by stone-age man. On a clear night, the stone-age sky above Lascaux would have contained many visible stars, on the order of thousands (visible to the naked eye). It would be difficult for the artist to paint every star on the cave wall, as the sky was presumably not visible from inside the cave. Furthermore, if the artist had painstakingly painted every star, the audience would not have learned something new about those stars (compared to simply going out at night and looking up). As a consequence, the artist had to make important decisions about \emph{which} stars to paint and \emph{how} to paint them. While the latter problem was presumably solved by painting dots and bovines, the first problem -- choosing which stars to paint -- was probably solved by first identifying the most salient stars on the night sky. Even today, these fundamental problems are studied in data visualization, known respectively as \emph{data abstraction} (e.g. selecting which stars to paint) and \emph{visual abstraction} (e.g. choosing appropriate star symbols)~\cite{stolte2003multiscale}.

Van Oosterom is a scientist who has studied zoomable interfaces. The concept of zoom applied to a cave wall interface, i.e. taking a step towards or away from the wall, has the effect that objects seem to become larger and smaller. However, the selection of stars and the way they are drawn does not change. Computers and computer screens enable what Van Oosterrom calls a \emph{logical zoom}~\cite{van1990reactive}. In response to a logical zoom operation, objects don't simply become larger or smaller. Instead, new data- and visual abstractions are computed and the result is presented on the screen. Of course, the new solution may equal the old solution, but this is rarely optimal as we will discuss in the following.

In 1961, Friedrich T\"{o}pfer formulated a principle that later became known as the \emph{Principle of Constant Information Density}~\cite{woodruff1998constant}. The principle states that the number of objects per display unit should remain constant under pan and zoom operations. The principle has been verified empirically many times, e.g. by counting the number of settlements shown on maps of Scotland at different scales~\cite{topfer1966principles}. It is not difficult to understand why this principle is true, since screens have a fixed number of pixels for rendering objects and sheets of paper have a fixed area on which to place ink. The principle applies both to data abstraction and visual abstraction.

%Back when the earth was believed to be flat, assuming that Eratosthenes was not around to suggest otherwise, 

\section{Modern-age Data Visualization}

\chapter{Multiscale Geographical Maps}
% section
Illustrate importance of multiscale visualization via reference to information cartography, data cube visualization, evolutionary timelines, social network visualizations and digital maps.

% section
\section{Principles}
Mention Weibel definition (salience etc). Reference woodruff and toepfer (constant information density). Reference da sarma (zoom consistency and visibility constraint). Reference samet (proximity constraint). Reference someone for topological constraints.
% section

\section{Multiscale Abstraction}
Define difference between data- and visual abstraction, reference data cube paper. Reuse points and figures from ICDE 2014 presentation (what to display versus how to display). Mention the geographical terms of model generalization and cartographic generalization (reference Gruenreich). 

\subsection{Data abstraction}
Mention that data abstraction for maps is surveyed in Part I chapter 1.

\subsubsection{}

\subsection{Visual abstraction}
Reference visual variables.

\section{Case Study: Danish Geodata Agency}
Mention GST and their use cases (POI and place names).

\chapter{Map Services}

\section{Map Services}
Talk about how map services are used.

\section{Case Study: Danish Geodata Agency}
Mention GST and their use cases (POI and place names).


\part{Producing Maps}

\chapter{Data abstraction methods for maps}
Survey the literature.

Reference Weibel and Harrie (constraint-based approach and salience). Reference Wollf (land use IP). Reference Da Sarma (fusion tables IP).


\chapter{}


\part{Serving Maps}

\bibliographystyle{plain}
\bibliography{thesis}
                             % Sample .bib file with references that match those in
                             % the 'Specifications Document (V1.5)' as well containing
                             % 'legacy' bibs and bibs with 'alternate codings'.
                             % Gerry Murray - March 2012



Marcos ambitious idea, three parts:
- (I) Introduction: talk about the two chapters that follow. 
- (P1) Pt 1: bulk: declarative cartography, about PRODUCING maps
- (P2) Pt 2: about SERVING digital maps
- Similar structure for both: state of the art, my contributions (advancing the state of the art).  

What-goes-where:
- I <- Case Study, P1 enables P2, Mention where related work is (which parts/chapters)
- P1 <- 
        Survey generalization, 
        CVL1 (closing the gap, part a), 
        CVL2 (closing the gap, part b)
- P2 <- 
        Survey on serving maps, getting to keyed data for maps, all this stuff you can use 
                incl. vectile (step 2),
                caching,
                prediction,
                data partitioning (step 3), 
                replication (step 4), 
                consistency, 
                key-value stores, 
                classic web serving infrastructures,
                papers from seminar
        Gap between state of the art, and the agency
        TileHeat (closing the gap, step 1), deploying a caching infrastructure
        
Publication strategy:

CVL2 (it's a journal thing, not a conference submission):
Approach: "Make CVL more general (star approach), with comparable performance"
- GeoInformatica (extended version of CVL), "completeness/thoroughness": repeat experiments, show new use cases (comp. to CVL), illustrate CVL2 with the new use cases 
- Only conference if "technical fun" or "something new" in compiler, real tech. take-away

\end{document}  

